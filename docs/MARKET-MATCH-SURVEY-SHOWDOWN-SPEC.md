# PLAYROOM — MARKET MATCH + SURVEY SHOWDOWN (Dev Spec v1)

**Goal:** Build two content-driven game systems with safe sourcing, verification, and scalable import.

**Relation to Activity Room:** Survey Showdown = live **Feud** MVP (see `ACTIVITY-ROOM-SPEC.md`). Market Match = content-backed **Estimation Show** (numeric/price guessing with sources). This spec defines the **content layer** and **data models** for both.

---

========================================================
A) MARKET MATCH (Historical Price Guessing)
========================================================

## A0) Product Summary

Market Match is a price/estimate game using:

- Historical consumer prices (stable facts), plus optional “as-of today” prices (manual entry)
- Optional photo prompts (public domain / properly licensed)

**Core loop:**

1. TV shows item image + prompt (“What did this cost in YEAR?”)
2. Players guess (numeric or tiered)
3. Reveal shows correct price + source citation + optional inflation-adjusted note

**Primary differentiator:** Focus on **historical price facts** to avoid constantly-changing “today” prices.

## A1) Content Strategy (Truth + Stability)

### v1 Recommended: “Historical Price Facts” packs

- **Staples:** bread, milk, eggs, gasoline, electricity, movie ticket, etc.
- **Consumer durables:** microwave, TV, car MSRP (when sourced), airfare averages (when sourced)
- **Experience prices:** movie ticket, popcorn, soda, concert ticket (requires good sources)

### Authoritative sources (priority order)

1. **BLS CPI Average Price Data** for many staples since 1980 (and notes about methodology). Store series ID + download snapshot.
2. **BLS via FRED** time series where available (gas, eggs, etc.).
3. **NBER Macrohistory (Prices)** for older historical retail price series.
4. Optional curated sources for movie tickets, cars MSRP, etc. (must be verifiable & stored w/ citation)

**Methodology note (display in admin):** BLS average price series have known methodology differences across eras; store `methodology_note` per source series.

## A2) Licensing Rules for Images (Non-negotiable)

- Every image asset MUST have:
  - license type (Public Domain / CC BY / CC BY-SA / etc.)
  - attribution text (if required)
  - source URL
- Prefer Public Domain or CC BY/CC BY-SA from reputable libraries.

## A3) Market Match Data Model (DB Schema)

### Tables

#### market_item

- `id` (uuid)
- `title` (e.g., “White bread, 1 lb.”)
- `category_tags[]` (food, fuel, housing, entertainment, tech, transport)
- `unit` (e.g., “per gallon”, “per ticket”, “per lb”, “per item”)
- `geography` (default “U.S. city average” if BLS)
- `notes_public` (short display note)
- `notes_admin` (internal)

#### market_price_fact

- `id` (uuid)
- `market_item_id` (fk)
- `year` (int) OR `date` (YYYY-MM) (support both)
- `price_usd` (decimal)
- `price_type` (average / median / MSRP / posted / estimated) — must be explicit
- `source_id` (fk)
- `citation_text` (short)
- `citation_url`
- `verification_status` (draft / verified / needs_review)
- `verified_by`
- `verified_at`
- `provenance_hash` (hash of the imported row, for audit)

#### source

- `id` (uuid)
- `source_name` (e.g., “BLS CPI Average Price Data”)
- `publisher` (BLS / NBER / etc.)
- `source_url`
- `license_notes` (for data usage terms)
- `methodology_note` (optional)
- `last_fetched_at`
- `snapshot_file_ref` (optional: store downloaded CSV/JSON snapshot)

#### media_asset

- `id` (uuid)
- `kind` (image)
- `source_url`
- `license` (PD / CC BY / CC BY-SA / etc.)
- `attribution_required` (bool)
- `attribution_text`
- `stored_asset_ref` (cloud/local)
- `review_status` (draft/verified)
- `verified_by`
- `verified_at`

#### market_prompt

(One “question card” instance; supports multiple ways to ask the same fact)

- `id` (uuid)
- `market_item_id`
- `price_fact_id` (fk)
- `prompt_template_id` (fk)
- `prompt_text` (rendered)
- `difficulty` (1–5)
- `audience_presets[]` (brewery/senior/school/corporate/sensory)
- `answer_mode` (numeric_entry / multiple_choice_tiers)
- `tiers[]` (if MC; generated by rules)
- `time_limit_suggested`
- `under_pressure_ok` (bool)
- `media_asset_id` (optional)
- `explanation_short`
- `fun_fact` (optional)

#### prompt_template

- `id` (uuid)
- `template_name` (e.g., “What did this cost in {YEAR}?”)
- `template_text`
- `allowed_units[]`
- `allowed_categories[]`
- `default_answer_mode`
- `tier_generation_rules` (json)

## A4) Tier Generation Rules (for multiple-choice price tiers)

Given correct price P:

- Create 4–6 options:
  - 1 correct
  - 3–5 decoys spaced by % (e.g., 0.6P, 0.8P, 1.2P, 1.5P) rounded to “nice” numbers
- Prevent absurd decoys (cap ranges by category)
- Ensure unique options after rounding

## A5) Pack Generation Rules

A “pack” = curated set of prompts:

- **market_pack:** name, audience preset, era range, categories included, question_count target

**Generation:**

- Filter verified facts only (default)
- Enforce variety:
  - categories variety
  - year spread (e.g., 1950s/70s/90s/2000s)
  - difficulty ramp
  - question type mix (numeric vs tiers)

## A6) Display Requirements (TV)

- Always show: item name + year/date, unit, “Source: ____” tiny footer (with abbreviated citation)
- Reveal shows: correct price, optional “This equals about ___ in today’s dollars” (ONLY if we have a verified CPI conversion module; otherwise omit)

## A7) Host Requirements

- Host can: choose pack (e.g., “1970s Grocery Prices”), toggle numeric vs tiers, toggle Under Pressure, input “today price” manually (optional mode), edit prompt wording (does not change fact record)

## A8) Printables

- Market Match cards (image + prompt + answer)
- Score sheet
- Source list page (optional) for transparency

## A9) TODO — MARKET MATCH (Dev Checklist)

- [ ] Implement DB tables above
- [ ] Build admin import pipeline (CSV/JSON) with source metadata capture
- [ ] Implement verification workflow (draft → verified)
- [ ] Implement tier generator
- [ ] Implement pack generator (constraints + variety)
- [ ] Implement TV/player/host UI flows
- [ ] Implement citations footer (abbreviated + link in host)
- [ ] Implement media asset licensing enforcement gate
- [ ] Implement printables export
- [ ] Create v1 starter datasets:
  - BLS staples since 1980 (bread/milk/eggs/gas etc.)
  - Gas series via FRED (BLS) where helpful
  - NBER macrohistory selected older retail price series

---

========================================================
B) SURVEY SHOWDOWN (Crowd-sourced prompt game)
========================================================

## B0) Product Summary

Survey Showdown is a prompt-driven game where:

- Players submit 1–3 short answers
- Host can cluster/merge similar answers
- TV reveals top answers with points by frequency (optional)
- Optional “Decision Funnel” (Top 8 → 4 → 2 → final pick)

**Two content lanes:**

1. **Global Prompt Library** (Playroom-provided, safe, broad)
2. **Local Prompt Packs** (brewery/school/corporate custom questions)

**Live implementation:** See Activity Room Feud MVP (`ACTIVITY-ROOM-SPEC.md` §8.1). This section defines the **content/prompt library** layer and DB model for packs and verified prompts.

## B1) Prompt Library Strategy

Prompts should be: short, friendly by default, tagged for audience presets, optionally marked “insightful” vs “silly”, editable by host at runtime.

**Prompt categories:**

- opinions (“best…”, “favorite…”)
- behaviors (“what do you do when…”)
- memories (decade-specific nostalgia prompts)
- business insights (menu ideas, event ideas)
- team-building (values, work culture)
- school-friendly (learning preferences, fun facts)

## B2) Survey Showdown Data Model

### Tables

#### survey_prompt

- `id` (uuid)
- `prompt_text`
- `prompt_type` (open_text / emoji / A_B / rank_choice / multi_choice)
- `answer_limit` (default 3)
- `character_limit` (default 24 per answer on TV)
- `audience_presets[]`
- `tags[]`
- `difficulty` (1–5, optional)
- `safety_profile` (all_ages / adults_only)
- `example_answers[]` (optional)
- `is_verified` (bool) — Playroom-curated

#### survey_session

- `id`
- `host_id`
- `prompt_id` (or ad-hoc prompt stored inline)
- `started_at` / `ended_at`
- `theme_id`
- `moderation_profile_id`
- `results_visibility` (aggregate_only / full_log)

#### survey_submission

- `id`
- `session_id`
- `player_id` (or anonymous)
- `answers[]` (1–3 strings)
- `created_at`

#### survey_cluster

- `id`
- `session_id`
- `canonical_answer` (string)
- `member_answers[]` (strings)
- `count` (int)
- `points` (int, if using frequency scoring)

## B3) Clustering & Merge Rules

- Auto-cluster suggestions: normalize (lowercase, trim, strip punctuation), simple stemming (optional), fuzzy match threshold (host adjustable)
- **Always allow host review:** show merged group + all originals; host can split/merge manually; keep full audit in host-only view

*(Live Feud already implements in-memory clustering + host audit drawer; this table model supports persistence and replay.)*

## B4) Display / Animation (Theme Toggle)

- Feud-style board: 8 slots, 2×4
- Reveal: flip plate hinge-down; optional cascade into slot below (theme toggle); optional bottom plate “drop off” (theme toggle)
- Prompt phase: prompt displayed + QR join + “submit up to 3”
- Reveal phase: hide QR (optional) or keep small for late joiners; show join count badge optional

*(Implemented in FeudDisplay + FeudHostPanel.)*

## B5) Host Controls

- Edit prompt text live, set answer limit (1–3), open/close submissions, merge/split clusters, lock Top 8, enable Decision Funnel
- Scoring mode: frequency points / flat points per revealed / no score
- Export results (CSV/JSON/PDF)

*(Most implemented; Decision Funnel and exports are roadmap.)*

## B6) Sourcing / Safety for Prompt Library

Prompts are not “facts,” but must be: non-hateful, audience-appropriate, tagged with safety profile, optionally “adults-only language allowed” but still block hate/harassment/threats.

## B7) Printables

- Prompt cards, answer sheets (no phone mode), bracket/funnel worksheet, “insights summary” sheet

## B8) TODO — SURVEY SHOWDOWN (Dev Checklist)

- [ ] Implement prompt library table + tags + audience presets
- [ ] Implement session + submissions + cluster tables (persistence beyond live game state)
- [x] Implement player submit flow (1–3 answers) — *live in Feud*
- [x] Implement auto-cluster suggestions + host merge UI — *live audit drawer*
- [x] Implement reveal board UI + theme toggles (cascade/drop) — *live*
- [ ] Implement Decision Funnel mode
- [ ] Implement exports + printables
- [ ] Seed v1 prompt packs: Brewery Fun, Brewery Insights, School Classroom, Senior Nostalgia, Corporate Culture

---

========================================================
C) Shared Content Pipeline (All 3 Games)
========================================================

## C1) Unified “Content Ingestion” Requirements

**Note:** **Crowd Control Trivia** uses a shared verified trivia DB (`trivia_question` / `source` / `media_asset`). See `docs/CROWD-CONTROL-TRIVIA-SPEC.md` §9 for the canonical trivia model and board-generation rules.

All content objects must support:

- verification status
- source metadata (when factual)
- audience preset tags
- licensing metadata (when media)

## C2) Admin Workflow (Suggested)

1. Import dataset (CSV/JSON) into staging
2. Auto-validate schema + required fields
3. Human review + verify (Jason moderator v1)
4. Publish to “verified library”
5. Generate packs + preview in UI
6. Export printables

## C3) Export / Import Formats (v1)

- JSON as canonical
- CSV as secondary for bulk imports
- Every export includes: source_id and citation text for factual items; license + attribution for images

---

*End of Market Match + Survey Showdown Spec v1*
